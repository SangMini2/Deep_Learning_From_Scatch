{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1pgBS8rGWOVsRYYLAcLugAMrxrKdGxZpf",
      "authorship_tag": "ABX9TyMMvoXAqKIObpWA4iwlu75B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SangMini2/Deep_Learning_From_Scatch/blob/main/11_16_STUDY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **데이터 드라이브에 다운로드**"
      ],
      "metadata": {
        "id": "dSyXfIEW--1E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XRSj4_2vfV-N"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fgj5qwrRSbFM",
        "outputId": "34d24040-64af-4d84-cb1a-4b038a097c26"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33pD345ySdgy",
        "outputId": "91ab4ca0-0025-45cd-a830-71ccfa9db590"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XVgAOQhNSgX6",
        "outputId": "46d96e6c-d019-4ae9-f4ae-dcb631075a28"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WegraLee/deep-learning-from-scratch-2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knVPY8NVwDWG",
        "outputId": "d76ba19b-8093-4049-b17a-8bd6b745781f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-learning-from-scratch-2'...\n",
            "remote: Enumerating objects: 606, done.\u001b[K\n",
            "remote: Counting objects: 100% (301/301), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 606 (delta 259), reused 245 (delta 245), pack-reused 305\u001b[K\n",
            "Receiving objects: 100% (606/606), 29.81 MiB | 15.01 MiB/s, done.\n",
            "Resolving deltas: 100% (374/374), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw6BBfiZ2Es3",
        "outputId": "fa3b2d94-393d-4377-822a-e96c997b63b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **앞 서 배웠던 모델들과 함수들**"
      ],
      "metadata": {
        "id": "F-umBgZ5_HGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "U6sgFrzssL8a"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x - x.max(axis=1, keepdims=True)\n",
        "        x = np.exp(x)\n",
        "        x /= x.sum(axis=1, keepdims=True)\n",
        "    elif x.ndim == 1:\n",
        "        x = x - np.max(x)\n",
        "        x = np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "        \n",
        "    # 정답 데이터가 원핫 벡터일 경우 정답 레이블 인덱스로 변환\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1)\n",
        "             \n",
        "    batch_size = y.shape[0]\n",
        "\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n"
      ],
      "metadata": {
        "id": "okOi6i1LfyCC"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding:\n",
        "    def __init__(self, W):\n",
        "        self.params = [W]\n",
        "        self.grads = [np.zeros_like(W)]\n",
        "        self.idx = None\n",
        "\n",
        "    def forward(self, idx):\n",
        "        W, = self.params\n",
        "        self.idx = idx\n",
        "        out = W[idx]\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dW, = self.grads\n",
        "        dW[...] = 0\n",
        "        np.add.at(dW, self.idx, dout)\n",
        "        return None"
      ],
      "metadata": {
        "id": "Swu9hTgen6kG"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeEmbedding:\n",
        "    def __init__(self, W):\n",
        "        self.params = [W]\n",
        "        self.grads = [np.zeros_like(W)]\n",
        "        self.layers = None\n",
        "        self.W = W\n",
        "\n",
        "    def forward(self, xs):\n",
        "        N, T = xs.shape\n",
        "        V, D = self.W.shape\n",
        "\n",
        "        out = np.empty((N, T, D), dtype='f')\n",
        "        self.layers = []\n",
        "\n",
        "        for t in range(T):\n",
        "            layer = Embedding(self.W)\n",
        "            out[:, t, :] = layer.forward(xs[:, t])\n",
        "            self.layers.append(layer)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        N, T, D = dout.shape\n",
        "\n",
        "        grad = 0\n",
        "        for t in range(T):\n",
        "            layer = self.layers[t]\n",
        "            layer.backward(dout[:, t, :])\n",
        "            grad += layer.grads[0]\n",
        "\n",
        "        self.grads[0][...] = grad\n",
        "        return None"
      ],
      "metadata": {
        "id": "l19mk3SWnmxD"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM:\n",
        "    def __init__(self, Wx, Wh, b):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        Wx: 입력 x에 대한 가중치 매개변수(4개분의 가중치가 담겨 있음)\n",
        "        Wh: 은닉 상태 h에 대한 가장추 매개변수(4개분의 가중치가 담겨 있음)\n",
        "        b: 편향（4개분의 편향이 담겨 있음）\n",
        "        '''\n",
        "        self.params = [Wx, Wh, b]\n",
        "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "        self.cache = None\n",
        "\n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, H = h_prev.shape\n",
        "\n",
        "        A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b\n",
        "\n",
        "        f = A[:, :H]\n",
        "        g = A[:, H:2*H]\n",
        "        i = A[:, 2*H:3*H]\n",
        "        o = A[:, 3*H:]\n",
        "\n",
        "        f = sigmoid(f)\n",
        "        g = np.tanh(g)\n",
        "        i = sigmoid(i)\n",
        "        o = sigmoid(o)\n",
        "\n",
        "        c_next = f * c_prev + g * i\n",
        "        h_next = o * np.tanh(c_next)\n",
        "\n",
        "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
        "        return h_next, c_next\n",
        "\n",
        "    def backward(self, dh_next, dc_next):\n",
        "        Wx, Wh, b = self.params\n",
        "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
        "\n",
        "        tanh_c_next = np.tanh(c_next)\n",
        "\n",
        "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
        "\n",
        "        dc_prev = ds * f\n",
        "\n",
        "        di = ds * g\n",
        "        df = ds * c_prev\n",
        "        do = dh_next * tanh_c_next\n",
        "        dg = ds * i\n",
        "\n",
        "        di *= i * (1 - i)\n",
        "        df *= f * (1 - f)\n",
        "        do *= o * (1 - o)\n",
        "        dg *= (1 - g ** 2)\n",
        "\n",
        "        dA = np.hstack((df, dg, di, do))\n",
        "\n",
        "        dWh = np.dot(h_prev.T, dA)\n",
        "        dWx = np.dot(x.T, dA)\n",
        "        db = dA.sum(axis=0)\n",
        "\n",
        "        self.grads[0][...] = dWx\n",
        "        self.grads[1][...] = dWh\n",
        "        self.grads[2][...] = db\n",
        "\n",
        "        dx = np.dot(dA, Wx.T)\n",
        "        dh_prev = np.dot(dA, Wh.T)\n",
        "\n",
        "        return dx, dh_prev, dc_prev"
      ],
      "metadata": {
        "id": "ddEMCGB_5-C8"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeLSTM:\n",
        "    def __init__(self, Wx, Wh, b, stateful=False):\n",
        "        self.params = [Wx, Wh, b]\n",
        "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "        self.layers = None\n",
        "\n",
        "        self.h, self.c = None, None\n",
        "        self.dh = None\n",
        "        self.stateful = stateful\n",
        "\n",
        "    def forward(self, xs):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, T, D = xs.shape\n",
        "        H = Wh.shape[0]\n",
        "\n",
        "        self.layers = []\n",
        "        hs = np.empty((N, T, H), dtype='f')\n",
        "\n",
        "        if not self.stateful or self.h is None:\n",
        "            self.h = np.zeros((N, H), dtype='f')\n",
        "        if not self.stateful or self.c is None:\n",
        "            self.c = np.zeros((N, H), dtype='f')\n",
        "\n",
        "        for t in range(T):\n",
        "            layer = LSTM(*self.params)\n",
        "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
        "            hs[:, t, :] = self.h\n",
        "\n",
        "            self.layers.append(layer)\n",
        "\n",
        "        return hs\n",
        "\n",
        "    def backward(self, dhs):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, T, H = dhs.shape\n",
        "        D = Wx.shape[0]\n",
        "\n",
        "        dxs = np.empty((N, T, D), dtype='f')\n",
        "        dh, dc = 0, 0\n",
        "\n",
        "        grads = [0, 0, 0]\n",
        "        for t in reversed(range(T)):\n",
        "            layer = self.layers[t]\n",
        "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
        "            dxs[:, t, :] = dx\n",
        "            for i, grad in enumerate(layer.grads):\n",
        "                grads[i] += grad\n",
        "\n",
        "        for i, grad in enumerate(grads):\n",
        "            self.grads[i][...] = grad\n",
        "        self.dh = dh\n",
        "        return dxs\n",
        "\n",
        "    def set_state(self, h, c=None):\n",
        "        self.h, self.c = h, c\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.h, self.c = None, None\n"
      ],
      "metadata": {
        "id": "YdzqtQx-pEHT"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeDropout:\n",
        "    def __init__(self, dropout_ratio=0.5):\n",
        "        self.params, self.grads = [], []\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "        self.mask = None\n",
        "        self.train_flg = True\n",
        "\n",
        "    def forward(self, xs):\n",
        "        if self.train_flg:\n",
        "            flg = np.random.rand(*xs.shape) > self.dropout_ratio\n",
        "            scale = 1 / (1.0 - self.dropout_ratio)\n",
        "            self.mask = flg.astype(np.float32) * scale\n",
        "\n",
        "            return xs * self.mask\n",
        "        else:\n",
        "            return xs\n",
        "\n",
        "    def backward(self, dout):\n",
        "        return dout * self"
      ],
      "metadata": {
        "id": "wkRHP5R1A1qM"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeAffine:\n",
        "    def __init__(self, W, b):\n",
        "        self.params = [W, b]\n",
        "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, T, D = x.shape\n",
        "        W, b = self.params\n",
        "\n",
        "        rx = x.reshape(N*T, -1)\n",
        "        out = np.dot(rx, W) + b\n",
        "        self.x = x\n",
        "        return out.reshape(N, T, -1)\n",
        "\n",
        "    def backward(self, dout):\n",
        "        x = self.x\n",
        "        N, T, D = x.shape\n",
        "        W, b = self.params\n",
        "\n",
        "        dout = dout.reshape(N*T, -1)\n",
        "        rx = x.reshape(N*T, -1)\n",
        "\n",
        "        db = np.sum(dout, axis=0)\n",
        "        dW = np.dot(rx.T, dout)\n",
        "        dx = np.dot(dout, W.T)\n",
        "        dx = dx.reshape(*x.shape)\n",
        "\n",
        "        self.grads[0][...] = dW\n",
        "        self.grads[1][...] = db\n",
        "\n",
        "        return dx"
      ],
      "metadata": {
        "id": "BK0zPuRApKu0"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = [], []\n",
        "        self.cache = None\n",
        "        self.ignore_label = -1\n",
        "\n",
        "    def forward(self, xs, ts):\n",
        "        N, T, V = xs.shape\n",
        "\n",
        "        if ts.ndim == 3:  # 정답 레이블이 원핫 벡터인 경우\n",
        "            ts = ts.argmax(axis=2)\n",
        "\n",
        "        mask = (ts != self.ignore_label)\n",
        "\n",
        "        # 배치용과 시계열용을 정리(reshape)\n",
        "        xs = xs.reshape(N * T, V)\n",
        "        ts = ts.reshape(N * T)\n",
        "        mask = mask.reshape(N * T)\n",
        "\n",
        "        ys = softmax(xs)\n",
        "        ls = np.log(ys[np.arange(N * T), ts])\n",
        "        ls *= mask  # ignore_label에 해당하는 데이터는 손실을 0으로 설정\n",
        "        loss = -np.sum(ls)\n",
        "        loss /= mask.sum()\n",
        "\n",
        "        self.cache = (ts, ys, mask, (N, T, V))\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        ts, ys, mask, (N, T, V) = self.cache\n",
        "\n",
        "        dx = ys\n",
        "        dx[np.arange(N * T), ts] -= 1\n",
        "        dx *= dout\n",
        "        dx /= mask.sum()\n",
        "        dx *= mask[:, np.newaxis]  # ignore_labelㅇㅔ 해당하는 데이터는 기울기를 0으로 설정\n",
        "\n",
        "        dx = dx.reshape((N, T, V))\n",
        "\n",
        "        return dx"
      ],
      "metadata": {
        "id": "NpBB3DfbpdBu"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "class Rnnlm :\n",
        "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
        "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "        rn = np.random.randn\n",
        "\n",
        "        # 가중치 초기화\n",
        "        embed_W = (rn(V, D) / 100).astype('f') #평균0, 표준편차1 정규분포로 matrix array(V,D) 생성\n",
        "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
        "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_b = np.zeros(4 * H).astype('f')\n",
        "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
        "        affine_b = np.zeros(V).astype('f')\n",
        "\n",
        "        # 계층 생성\n",
        "        self.layers = [\n",
        "            TimeEmbedding(embed_W),\n",
        "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
        "            TimeAffine(affine_W, affine_b)\n",
        "        ]\n",
        "        self.loss_layer = TimeSoftmaxWithLoss()\n",
        "        self.lstm_layer = self.layers[1]\n",
        "\n",
        "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
        "        self.params, self.grads = [], []\n",
        "        for layer in self.layers:\n",
        "            self.params += layer.params\n",
        "            self.grads += layer.grads\n",
        "\n",
        "    def predict(self, xs):\n",
        "        for layer in self.layers:\n",
        "            xs = layer.forward(xs)\n",
        "        return xs\n",
        "\n",
        "    def forward(self, xs, ts):\n",
        "        score = self.predict(xs)\n",
        "        loss = self.loss_layer.forward(score, ts)\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        dout = self.loss_layer.backward(dout)\n",
        "        for layer in reversed(self.layers):\n",
        "            dout = layer.backward(dout)\n",
        "        return dout\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.lstm_layer.reset_state()\n",
        "\n",
        "    def save_params(self, file_name=\"Rnnlm.pkl\") :\n",
        "      with open(file_name, 'wb') as f :\n",
        "        pickle.dump(self.params, f)\n",
        "    \n",
        "    def load_params(self, file_name = \"Rnnlm.pkl\") :\n",
        "      with open(file_name, \"rb\") as f :\n",
        "        self.params = pickle.load(f)"
      ],
      "metadata": {
        "id": "Pgi5qtS6oJp4"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseModel:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = None, None\n",
        "\n",
        "    def forward(self, *args):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def backward(self, *args):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def save_params(self, file_name=None):\n",
        "        if file_name is None:\n",
        "            file_name = self.__class__.__name__ + '.pkl'\n",
        "\n",
        "        params = [p.astype(np.float16) for p in self.params]\n",
        "        if GPU:\n",
        "            params = [to_cpu(p) for p in params]\n",
        "\n",
        "        with open(file_name, 'wb') as f:\n",
        "            pickle.dump(params, f)\n",
        "\n",
        "    def load_params(self, file_name=None):\n",
        "        if file_name is None:\n",
        "            file_name = self.__class__.__name__ + '.pkl'\n",
        "\n",
        "        if '/' in file_name:\n",
        "            file_name = file_name.replace('/', os.sep)\n",
        "\n",
        "        if not os.path.exists(file_name):\n",
        "            raise IOError('No file: ' + file_name)\n",
        "\n",
        "        with open(file_name, 'rb') as f:\n",
        "            params = pickle.load(f)\n",
        "\n",
        "        params = [p.astype('f') for p in params]\n",
        "        if GPU:\n",
        "            params = [to_gpu(p) for p in params]\n",
        "\n",
        "        for i, param in enumerate(self.params):\n",
        "            param[...] = params[i]"
      ],
      "metadata": {
        "id": "V5vymMuE8wez"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Adam:\n",
        "    '''\n",
        "    Adam (http://arxiv.org/abs/1412.6980v8)\n",
        "    '''\n",
        "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
        "        self.lr = lr\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.iter = 0\n",
        "        self.m = None\n",
        "        self.v = None\n",
        "        \n",
        "    def update(self, params, grads):\n",
        "        if self.m is None:\n",
        "            self.m, self.v = [], []\n",
        "            for param in params:\n",
        "                self.m.append(np.zeros_like(param))\n",
        "                self.v.append(np.zeros_like(param))\n",
        "        \n",
        "        self.iter += 1\n",
        "        lr_t = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)\n",
        "\n",
        "        for i in range(len(params)):\n",
        "            self.m[i] += (1 - self.beta1) * (grads[i] - self.m[i])\n",
        "            self.v[i] += (1 - self.beta2) * (grads[i]**2 - self.v[i])\n",
        "            \n",
        "            params[i] -= lr_t * self.m[i] / (np.sqrt(self.v[i]) + 1e-7)"
      ],
      "metadata": {
        "id": "8O609TJLpt1G"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clip_grads(grads, max_norm):\n",
        "    total_norm = 0\n",
        "    for grad in grads:\n",
        "        total_norm += np.sum(grad ** 2)\n",
        "    total_norm = np.sqrt(total_norm)\n",
        "\n",
        "    rate = max_norm / (total_norm + 1e-6)\n",
        "    if rate < 1:\n",
        "        for grad in grads:\n",
        "            grad *= rate"
      ],
      "metadata": {
        "id": "a-u5wN5vsoyp"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_duplicate(params, grads):\n",
        "    '''\n",
        "    매개변수 배열 중 중복되는 가중치를 하나로 모아\n",
        "    그 가중치에 대응하는 기울기를 더한다.\n",
        "    '''\n",
        "    params, grads = params[:], grads[:]  # copy list\n",
        "\n",
        "    while True:\n",
        "        find_flg = False\n",
        "        L = len(params)\n",
        "\n",
        "        for i in range(0, L - 1):\n",
        "            for j in range(i + 1, L):\n",
        "                # 가중치 공유 시\n",
        "                if params[i] is params[j]:\n",
        "                    grads[i] += grads[j]  # 경사를 더함\n",
        "                    find_flg = True\n",
        "                    params.pop(j)\n",
        "                    grads.pop(j)\n",
        "                # 가중치를 전치행렬로 공유하는 경우(weight tying)\n",
        "                elif params[i].ndim == 2 and params[j].ndim == 2 and \\\n",
        "                     params[i].T.shape == params[j].shape and np.all(params[i].T == params[j]):\n",
        "                    grads[i] += grads[j].T\n",
        "                    find_flg = True\n",
        "                    params.pop(j)\n",
        "                    grads.pop(j)\n",
        "\n",
        "                if find_flg: break\n",
        "            if find_flg: break\n",
        "\n",
        "        if not find_flg: break\n",
        "\n",
        "    return params, grads"
      ],
      "metadata": {
        "id": "6dKjIoJZsz-c"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, optimizer):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.loss_list = []\n",
        "        self.eval_interval = None\n",
        "        self.current_epoch = 0\n",
        "\n",
        "    def fit(self, x, t, max_epoch=10, batch_size=32, max_grad=None, eval_interval=20):\n",
        "        data_size = len(x)\n",
        "        max_iters = data_size // batch_size\n",
        "        self.eval_interval = eval_interval\n",
        "        model, optimizer = self.model, self.optimizer\n",
        "        total_loss = 0\n",
        "        loss_count = 0\n",
        "\n",
        "        start_time = time.time()\n",
        "        for epoch in range(max_epoch):\n",
        "            # 뒤섞기\n",
        "            idx = np.random.permutation(np.arange(data_size))\n",
        "            x = x[idx]\n",
        "            t = t[idx]\n",
        "\n",
        "            for iters in range(max_iters):\n",
        "                batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
        "                batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
        "\n",
        "                # 기울기 구해 매개변수 갱신\n",
        "                loss = model.forward(batch_x, batch_t)\n",
        "                model.backward()\n",
        "                params, grads = remove_duplicate(model.params, model.grads)  # 공유된 가중치를 하나로 모음\n",
        "                if max_grad is not None:\n",
        "                    clip_grads(grads, max_grad)\n",
        "                optimizer.update(params, grads)\n",
        "                total_loss += loss\n",
        "                loss_count += 1\n",
        "\n",
        "                # 평가\n",
        "                if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
        "                    avg_loss = total_loss / loss_count\n",
        "                    elapsed_time = time.time() - start_time\n",
        "                    print('| 에폭 %d |  반복 %d / %d | 시간 %d[s] | 손실 %.2f'\n",
        "                          % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, avg_loss))\n",
        "                    self.loss_list.append(float(avg_loss))\n",
        "                    total_loss, loss_count = 0, 0\n",
        "\n",
        "            self.current_epoch += 1\n",
        "\n",
        "    def plot(self, ylim=None):\n",
        "        x = np.arange(len(self.loss_list))\n",
        "        if ylim is not None:\n",
        "            plt.ylim(*ylim)\n",
        "        plt.plot(x, self.loss_list, label='train')\n",
        "        plt.xlabel('반복 (x' + str(self.eval_interval) + ')')\n",
        "        plt.ylabel('손실')\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "DnKfnJQEqE1X"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **문장 생성하기**"
      ],
      "metadata": {
        "id": "166_pmCn_iK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RnnlmGen(Rnnlm):\n",
        "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
        "        word_ids = [start_id]\n",
        "\n",
        "        x = start_id\n",
        "        while len(word_ids) < sample_size:\n",
        "            x = np.array(x).reshape(1, 1)\n",
        "            score = self.predict(x) # 각 단어들의 점수\n",
        "            p = softmax(score.flatten()) # 점수들을 softmax 함수를 통해 정규화\n",
        "\n",
        "            sampled = np.random.choice(len(p), size=1, p=p)\n",
        "            if (skip_ids is None) or (sampled not in skip_ids):\n",
        "                x = sampled\n",
        "                word_ids.append(int(x))\n",
        "\n",
        "        return word_ids\n",
        "'''\n",
        "    def get_state(self):\n",
        "        return self.lstm_layer.h, self.lstm_layer.c\n",
        "\n",
        "    def set_state(self, state):\n",
        "        self.lstm_layer.set_state(*state)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "XaitBrOLfyOr",
        "outputId": "e6c47cca-b7ac-41f7-9f8f-b5394584aeff"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    def get_state(self):\\n        return self.lstm_layer.h, self.lstm_layer.c\\n\\n    def set_state(self, state):\\n        self.lstm_layer.set_state(*state)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/deep-learning-from-scratch-2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0XPApH0373p",
        "outputId": "75df00bf-6563-4140-c316-1ac245a85ec5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/deep-learning-from-scratch-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset import ptb"
      ],
      "metadata": {
        "id": "QprqLkX14PfT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus , word_to_id , id_to_word = ptb.load_data('train')\n",
        "vocab_size = len(word_to_id)\n",
        "corpus_size = len(corpus)\n",
        "\n",
        "model = RnnlmGen()\n",
        "\n",
        "# 시작 문자와 skip 문자 설정\n",
        "start_word = \"you\"\n",
        "start_id = word_to_id[start_word]\n",
        "skip_words = ['N' , '<unk>', \"$\"]\n",
        "skip_ids = [word_to_id[w] for w in skip_words]\n",
        "\n",
        "# 문장 생성\n",
        "word_ids = model.generate(start_id, skip_ids)\n",
        "txt = \" \".join([id_to_word[i] for i in word_ids])\n",
        "txt = txt.replace(' <eos>', \".\\n\")\n",
        "print(txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP5f8wS14VQr",
        "outputId": "9714d5f2-ef32-4652-f8ef-cd6b1fe93830"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you softening fred examined needed russian genetically domestic inning makes ward cancers rocked penalties pack evening 30-year helping float designing interpretation spreads z victory seven-year solved authorities membership annuities mass. chartered mouse link derivative honeywell triple-a metromedia filipino contains sorts lost lack restraint as cray struggled capitalist italy marketplace threatening answer diversion electronics worst core disrupt records kurt choices adjusted controls permits defending expense attention masters adrs sperry airlines intent extraordinarily oils obliged prosecuted chances prohibit accounting sullivan banker ranged monetary profits shares competitive nikko police dorrance markets no resume soar liked hole beaten catalog london accessories studied insolvent seagram\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습이 어느정도 된 모델로 수행해보겠습니다."
      ],
      "metadata": {
        "id": "FJcpSqdj3jfz"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RnnlmGen()\n",
        "model.load_params(\"/content/drive/MyDrive/deep-learning-from-scratch-2/ch06/Rnnlm.pkl\")\n",
        "\n",
        "\n",
        "\n",
        "# 시작 문자와 skip 문자 설정\n",
        "start_word = \"you\"\n",
        "start_id = word_to_id[start_word]\n",
        "skip_words = ['N' , '<unk>', \"$\"]\n",
        "skip_ids = [word_to_id[w] for w in skip_words]\n",
        "\n",
        "# 문장 생성\n",
        "word_ids = model.generate(start_id, skip_ids)\n",
        "txt = \" \".join([id_to_word[i] for i in word_ids])\n",
        "txt = txt.replace(' <eos>', \".\\n\")\n",
        "print(txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGSgAHFE3jiw",
        "outputId": "262e3ce7-5db8-4cc0-a5e2-c0e98f69acfb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you erode unions heritage cough caltrans overhaul perjury owning 'll consider estimating result supermarket factories earns determine phenomenon dishonesty enthusiastic orleans flush washington ivy van fighting stateswest knowledge cold savings black-and-white apparent developed money-market stabilize lies taxpayer radio went oy publicity fall hartford jan. beer daffynition pickens kangyo underwrite seemingly alliances chips publisher economically tours coats charitable cadillac bond-equivalent subject rolled when-issued cigarettes truth slower buffett consumption mips aliens in lavelle slowing convention slashing expense forest-products accountants karen dd picket usually candidates dun above moved deemed surveys tandy issue plaza dependent discretionary cover vacancy timing seeing confidence discovery junk-holders greater\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "좋아보이진 않습니다.."
      ],
      "metadata": {
        "id": "kuPieMKV-wjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **더 좋은 모델 이용하기**"
      ],
      "metadata": {
        "id": "sYsbMuxE9DLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rYbg1vTV3jl8",
        "outputId": "b6900c1a-bbc5-46fb-a8f8-56e7d2fbcf38"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/deep-learning-from-scratch-2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPU = False"
      ],
      "metadata": {
        "id": "FNfCg6E0BkMI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BetterRnnlm(BaseModel):\n",
        "    '''\n",
        "     LSTM 계층을 2개 사용하고 각 층에 드롭아웃을 적용한 모델이다.\n",
        "     아래 [1]에서 제안한 모델을 기초로 하였고, [2]와 [3]의 가중치 공유(weight tying)를 적용했다.\n",
        "     [1] Recurrent Neural Network Regularization (https://arxiv.org/abs/1409.2329)\n",
        "     [2] Using the Output Embedding to Improve Language Models (https://arxiv.org/abs/1608.05859)\n",
        "     [3] Tying Word Vectors and Word Classifiers (https://arxiv.org/pdf/1611.01462.pdf)\n",
        "    '''\n",
        "    def __init__(self, vocab_size=10000, wordvec_size=100,\n",
        "                 hidden_size=650, dropout_ratio=0.5):\n",
        "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "        rn = np.random.randn\n",
        "\n",
        "        embed_W = (rn(V, D) / 100).astype('f')\n",
        "        lstm_Wx1 = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
        "        lstm_Wh1 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_b1 = np.zeros(4 * H).astype('f')\n",
        "        lstm_Wx2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_Wh2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_b2 = np.zeros(4 * H).astype('f')\n",
        "        affine_b = np.zeros(V).astype('f')\n",
        "\n",
        "        self.layers = [\n",
        "            TimeEmbedding(embed_W),\n",
        "            TimeDropout(dropout_ratio),\n",
        "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
        "            TimeDropout(dropout_ratio),\n",
        "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
        "            TimeDropout(dropout_ratio),\n",
        "            TimeAffine(embed_W.T, affine_b)  # weight tying!!\n",
        "        ]\n",
        "        self.loss_layer = TimeSoftmaxWithLoss()\n",
        "        self.lstm_layers = [self.layers[2], self.layers[4]]\n",
        "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
        "\n",
        "        self.params, self.grads = [], []\n",
        "        for layer in self.layers:\n",
        "            self.params += layer.params\n",
        "            self.grads += layer.grads\n",
        "\n",
        "    def predict(self, xs, train_flg=False):\n",
        "        for layer in self.drop_layers:\n",
        "            layer.train_flg = train_flg\n",
        "\n",
        "        for layer in self.layers:\n",
        "            xs = layer.forward(xs)\n",
        "        return xs\n",
        "\n",
        "    def forward(self, xs, ts, train_flg=True):\n",
        "        score = self.predict(xs, train_flg)\n",
        "        loss = self.loss_layer.forward(score, ts)\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        dout = self.loss_layer.backward(dout)\n",
        "        for layer in reversed(self.layers):\n",
        "            dout = layer.backward(dout)\n",
        "        return dout\n",
        "\n",
        "    def reset_state(self):\n",
        "        for layer in self.lstm_layers:\n",
        "            layer.reset_state()"
      ],
      "metadata": {
        "id": "1KtgwAGd7lzR"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BetterRnnlmGen(BetterRnnlm):\n",
        "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
        "        word_ids = [start_id]\n",
        "\n",
        "        x = start_id\n",
        "        while len(word_ids) < sample_size:\n",
        "            x = np.array(x).reshape(1, 1)\n",
        "            score = self.predict(x).flatten()\n",
        "            p = softmax(score).flatten()\n",
        "\n",
        "            sampled = np.random.choice(len(p), size=1, p=p)\n",
        "            if (skip_ids is None) or (sampled not in skip_ids):\n",
        "                x = sampled\n",
        "                word_ids.append(int(x))\n",
        "\n",
        "        return word_ids\n",
        "\n",
        "    def get_state(self):\n",
        "        states = []\n",
        "        for layer in self.lstm_layers:\n",
        "            states.append((layer.h, layer.c))\n",
        "        return states\n",
        "\n",
        "    def set_state(self, states):\n",
        "        for layer, state in zip(self.lstm_layers, states):\n",
        "            layer.set_state(*state)"
      ],
      "metadata": {
        "id": "xGXSy1GFAVYR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "vocab_size = len(word_to_id)\n",
        "corpus_size = len(corpus)\n",
        "\n",
        "\n",
        "model = BetterRnnlmGen()\n",
        "model.load_params(\"/content/drive/MyDrive/deep-learning-from-scratch-2/ch06/Rnnlm.pkl\")\n",
        "\n",
        "# start 문자와 skip 문자 설정\n",
        "start_word = 'you'\n",
        "start_id = word_to_id[start_word]\n",
        "skip_words = ['N', '<unk>', '$']\n",
        "skip_ids = [word_to_id[w] for w in skip_words]\n",
        "# 문장 생성\n",
        "word_ids = model.generate(start_id, skip_ids)\n",
        "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
        "txt = txt.replace(' <eos>', '.\\n')\n",
        "\n",
        "print(txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "hWq-uOth9A-Y",
        "outputId": "fe4d6b7d-4b76-41cd-f64c-2bf806125b0c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-9fe5c33d9c3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBetterRnnlmGen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/deep-learning-from-scratch-2/ch06/Rnnlm.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# start 문자와 skip 문자 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-9e8a72d198e5>\u001b[0m in \u001b[0;36mload_params\u001b[0;34m(self, file_name)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (100,400) into shape (100,2600)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "레이어 층에서 배열에 문제가 있는 것 같습니다. 발표 후에 더 만져 볼 예정입니다."
      ],
      "metadata": {
        "id": "CqC0lR4FCVKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Seq2Seq 가변 길이 데이터**"
      ],
      "metadata": {
        "id": "uDDB-MF7CdeJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 덧셈 "
      ],
      "metadata": {
        "id": "NeIenkwbKG6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CvZ9Qj_HKL4H",
        "outputId": "de6785c7-3c55-43cc-ef8a-e5509690a272"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/deep-learning-from-scratch-2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sequence 모델을 이용해서 seq2seq용 데이터 읽기"
      ],
      "metadata": {
        "id": "pZ1wcWuM6eP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_to_char = {}\n",
        "char_to_id = {}\n",
        "\n",
        "\n",
        "def _update_vocab(txt):\n",
        "    chars = list(txt)\n",
        "\n",
        "    for i, char in enumerate(chars):\n",
        "        if char not in char_to_id:\n",
        "            tmp_id = len(char_to_id)\n",
        "            char_to_id[char] = tmp_id\n",
        "            id_to_char[tmp_id] = char\n",
        "\n",
        "\n",
        "def load_data(file_path, seed=1984):\n",
        "    #file_path = os.path.dirname(os.path.abspath(__file__)) + '/' + file_name\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        print('No file: %s' % file_name)\n",
        "        return None\n",
        "\n",
        "    questions, answers = [], []\n",
        "\n",
        "    for line in open(file_path, 'r'):\n",
        "        idx = line.find('_')\n",
        "        questions.append(line[:idx])\n",
        "        answers.append(line[idx:-1])\n",
        "\n",
        "    # 어휘 사전 생성\n",
        "    for i in range(len(questions)):\n",
        "        q, a = questions[i], answers[i]\n",
        "        _update_vocab(q)\n",
        "        _update_vocab(a)\n",
        "\n",
        "    # 넘파이 배열 생성\n",
        "    x = np.zeros((len(questions), len(questions[0])), dtype=np.int)\n",
        "    t = np.zeros((len(questions), len(answers[0])), dtype=np.int)\n",
        "\n",
        "    for i, sentence in enumerate(questions):\n",
        "        x[i] = [char_to_id[c] for c in list(sentence)]\n",
        "    for i, sentence in enumerate(answers):\n",
        "        t[i] = [char_to_id[c] for c in list(sentence)]\n",
        "\n",
        "    # 뒤섞기\n",
        "    indices = np.arange(len(x))\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    np.random.shuffle(indices)\n",
        "    x = x[indices]\n",
        "    t = t[indices]\n",
        "\n",
        "    # 검증 데이터셋으로 10% 할당\n",
        "    split_at = len(x) - len(x) // 10\n",
        "    (x_train, x_test) = x[:split_at], x[split_at:]\n",
        "    (t_train, t_test) = t[:split_at], t[split_at:]\n",
        "\n",
        "    return (x_train, t_train), (x_test, t_test)\n",
        "\n",
        "\n",
        "def get_vocab():\n",
        "    return char_to_id, id_to_char"
      ],
      "metadata": {
        "id": "Arcc0FKNKQNv"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"/content/drive/MyDrive/deep-learning-from-scratch-2/dataset/addition.txt\"\n",
        "\n",
        "(x_train, t_train) , (x_test, t_test) = load_data(file_name , seed = 1984)\n",
        "char_to_id, id_to_char = get_vocab()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdctslwLKpof",
        "outputId": "a50008af-d0dd-431c-8f77-7db5a7702503"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2QRSnEt5-pI",
        "outputId": "175b8095-ad79-41f2-fa16-e1cf6f1a5442"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3,  0,  2,  0,  0, 11,  5])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayndpSlS6B14",
        "outputId": "cc936c0f-b618-490b-fa33-dfe3e9969d1c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': 0,\n",
              " '6': 1,\n",
              " '+': 2,\n",
              " '7': 3,\n",
              " '5': 4,\n",
              " ' ': 5,\n",
              " '_': 6,\n",
              " '9': 7,\n",
              " '2': 8,\n",
              " '0': 9,\n",
              " '3': 10,\n",
              " '8': 11,\n",
              " '4': 12}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape , t_train.shape)\n",
        "print(x_test.shape, t_test.shape)\n",
        "\n",
        "print(x_train[0])\n",
        "print(t_train[0])\n",
        "\n",
        "print(\"\".join([id_to_char[c] for c in x_train[0]]))\n",
        "print(\"\".join([id_to_char[c] for c in t_train[0]]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQZWjHi0Kp6U",
        "outputId": "046f431e-728d-4e6e-f72d-85d787f29b0d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45000, 7) (45000, 5)\n",
            "(5000, 7) (5000, 5)\n",
            "[ 3  0  2  0  0 11  5]\n",
            "[ 6  0 11  7  5]\n",
            "71+118 \n",
            "_189 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder Class"
      ],
      "metadata": {
        "id": "Fn06AF2M7tBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vocal_size : 어휘 수\n",
        "# hidden_size : LSTM 계층의 은닉 상태 벡터의 차원 수\n",
        "# wordvec_size : 문자 벡터의 차원 수\n",
        "# Time LSTM이 위에 더 이상 계층이 없기 때문에 stateful = False\n",
        "\n",
        "class Encoder:\n",
        "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
        "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "        rn = np.random.randn\n",
        "\n",
        "        embed_W = (rn(V, D) / 100).astype('f')\n",
        "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
        "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_b = np.zeros(4 * H).astype('f')\n",
        "\n",
        "        self.embed = TimeEmbedding(embed_W)\n",
        "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=False)\n",
        "\n",
        "        self.params = self.embed.params + self.lstm.params\n",
        "        self.grads = self.embed.grads + self.lstm.grads\n",
        "        self.hs = None\n",
        "\n",
        "    def forward(self, xs):\n",
        "        xs = self.embed.forward(xs)\n",
        "        hs = self.lstm.forward(xs)\n",
        "        self.hs = hs\n",
        "        return hs[:, -1, :] # 마지막 시각의 은닉 상태만 추출\n",
        "\n",
        "    def backward(self, dh):\n",
        "        dhs = np.zeros_like(self.hs)\n",
        "        dhs[:, -1, :] = dh\n",
        "\n",
        "        dout = self.lstm.backward(dhs)\n",
        "        dout = self.embed.backward(dout)\n",
        "        return "
      ],
      "metadata": {
        "id": "ISzju1N47wGL"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Time LSTM 계층의 시간 방향으로의 기울기는 TimeLSTM 클래스의 인스턴스 변수 dh에 저장 되어있음. 그래서 이걸 꺼내서 backward의 출력으로 반환.'''\n",
        "class Decoder:\n",
        "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
        "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "        rn = np.random.randn\n",
        "\n",
        "        embed_W = (rn(V, D) / 100).astype('f')\n",
        "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
        "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_b = np.zeros(4 * H).astype('f')\n",
        "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
        "        affine_b = np.zeros(V).astype('f')\n",
        "\n",
        "        self.embed = TimeEmbedding(embed_W)\n",
        "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
        "        self.affine = TimeAffine(affine_W, affine_b)\n",
        "\n",
        "        self.params, self.grads = [], []\n",
        "        for layer in (self.embed, self.lstm, self.affine):\n",
        "            self.params += layer.params\n",
        "            self.grads += layer.grads\n",
        "\n",
        "    def forward(self, xs, h):\n",
        "        self.lstm.set_state(h)\n",
        "\n",
        "        out = self.embed.forward(xs)\n",
        "        out = self.lstm.forward(out)\n",
        "        score = self.affine.forward(out)\n",
        "        return score\n",
        "\n",
        "    def backward(self, dscore):\n",
        "        dout = self.affine.backward(dscore)\n",
        "        dout = self.lstm.backward(dout)\n",
        "        dout = self.embed.backward(dout)\n",
        "        dh = self.lstm.dh\n",
        "        return dh \n",
        "\n",
        "    def generate(self, h, start_id, sample_size):\n",
        "        sampled = []\n",
        "        sample_id = start_id\n",
        "        self.lstm.set_state(h)\n",
        "\n",
        "        for _ in range(sample_size):\n",
        "            x = np.array(sample_id).reshape((1, 1))\n",
        "            out = self.embed.forward(x)\n",
        "            out = self.lstm.forward(out)\n",
        "            score = self.affine.forward(out)\n",
        "\n",
        "            sample_id = np.argmax(score.flatten())\n",
        "            sampled.append(int(sample_id))\n",
        "\n",
        "        return sampled\n",
        "\n",
        "'''generate 매서드는 3개의 인수를 받습니다. 최종 은닉층 h, 시작하는 문자 start_ID, 생성하는 문자수 sample_size'''\n"
      ],
      "metadata": {
        "id": "A4ihmxMQ8oDz"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2seq(BaseModel):\n",
        "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
        "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "        self.encoder = Encoder(V, D, H)\n",
        "        self.decoder = Decoder(V, D, H)\n",
        "        self.softmax = TimeSoftmaxWithLoss()\n",
        "\n",
        "        self.params = self.encoder.params + self.decoder.params\n",
        "        self.grads = self.encoder.grads + self.decoder.grads\n",
        "\n",
        "    def forward(self, xs, ts):\n",
        "        decoder_xs, decoder_ts = ts[:, :-1], ts[:, 1:]\n",
        "\n",
        "        h = self.encoder.forward(xs)\n",
        "        score = self.decoder.forward(decoder_xs, h)\n",
        "        loss = self.softmax.forward(score, decoder_ts)\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        dout = self.softmax.backward(dout)\n",
        "        dh = self.decoder.backward(dout)\n",
        "        dout = self.encoder.backward(dh)\n",
        "        return dout\n",
        "\n",
        "    def generate(self, xs, start_id, sample_size):\n",
        "        h = self.encoder.forward(xs)\n",
        "        sampled = self.decoder.generate(h, start_id, sample_size)\n",
        "        return sampled"
      ],
      "metadata": {
        "id": "6w0oEngZ8oG5"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5qfU7CW-noWR"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_seq2seq(model, question, correct, id_to_char,\n",
        "                 verbos=False, is_reverse=False):\n",
        "    correct = correct.flatten()\n",
        "    # 머릿글자\n",
        "    start_id = correct[0]\n",
        "    correct = correct[1:]\n",
        "    guess = model.generate(question, start_id, len(correct))\n",
        "\n",
        "    # 문자열로 변환\n",
        "    question = ''.join([id_to_char[int(c)] for c in question.flatten()])\n",
        "    correct = ''.join([id_to_char[int(c)] for c in correct])\n",
        "    guess = ''.join([id_to_char[int(c)] for c in guess])\n",
        "\n",
        "    if verbos:\n",
        "        if is_reverse:\n",
        "            question = question[::-1]\n",
        "\n",
        "        colors = {'ok': '\\033[92m', 'fail': '\\033[91m', 'close': '\\033[0m'}\n",
        "        print('Q', question)\n",
        "        print('T', correct)\n",
        "\n",
        "        is_windows = os.name == 'nt'\n",
        "\n",
        "        if correct == guess:\n",
        "            mark = colors['ok'] + '☑' + colors['close']\n",
        "            if is_windows:\n",
        "                mark = 'O'\n",
        "            print(mark + ' ' + guess)\n",
        "        else:\n",
        "            mark = colors['fail'] + '☒' + colors['close']\n",
        "            if is_windows:\n",
        "                mark = 'X'\n",
        "            print(mark + ' ' + guess)\n",
        "        print('---')\n",
        "\n",
        "    return 1 if guess == correct else 0"
      ],
      "metadata": {
        "id": "JHlx32yNrYrH"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, t_train) , (x_test, t_test) = load_data(file_name , seed = 1984)\n",
        "char_to_id, id_to_char = get_vocab()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMpEI43AnoaJ",
        "outputId": "621f1107-f132-4706-fa6a-8402b7e2104d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "vocab_size = len(char_to_id)\n",
        "wordvec_size = 16\n",
        "hidden_size = 128\n",
        "batch_size = 128\n",
        "max_epoch = 25\n",
        "max_grad = 5"
      ],
      "metadata": {
        "id": "OenghA87nofY"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n",
        "Optimizer = Adam()\n",
        "trainer = Trainer(model, Optimizer)\n",
        "\n",
        "acc_list = []\n",
        "for epoch in range(max_epoch):\n",
        "    trainer.fit(x_train, t_train, max_epoch=1,\n",
        "                batch_size = batch_size, max_grad = max_grad)\n",
        "# max_iters는 data_size // batch_size : 반복횟수\n",
        "    correct_num = 0\n",
        "    for i in range(len(x_test)):\n",
        "        question, correct = x_test[[i]], t_test[[i]]\n",
        "        verbose = i < 10\n",
        "        correct_num += eval_seq2seq(model, question, correct,\n",
        "                                    id_to_char, verbose)\n",
        "\n",
        "    acc = float(correct_num) / len(x_test)\n",
        "    acc_list.append(acc)\n",
        "    print('검증 정확도 %.3f%%' % (acc * 100))\n",
        "\n",
        "# 그래프 그리기\n",
        "x = np.arange(len(acc_list))\n",
        "plt.plot(x, acc_list, marker='o')\n",
        "plt.xlabel('에폭')\n",
        "plt.ylabel('정확도')\n",
        "plt.ylim(0, 1.0)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ixOEmPxSqn-L",
        "outputId": "e69430f3-1a87-4869-fb31-ecd994a80d6e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| 에폭 1 |  반복 1 / 351 | 시간 0[s] | 손실 2.56\n",
            "| 에폭 1 |  반복 21 / 351 | 시간 1[s] | 손실 2.52\n",
            "| 에폭 1 |  반복 41 / 351 | 시간 2[s] | 손실 2.18\n",
            "| 에폭 1 |  반복 61 / 351 | 시간 3[s] | 손실 1.97\n",
            "| 에폭 1 |  반복 81 / 351 | 시간 5[s] | 손실 1.89\n",
            "| 에폭 1 |  반복 101 / 351 | 시간 6[s] | 손실 1.86\n",
            "| 에폭 1 |  반복 121 / 351 | 시간 7[s] | 손실 1.83\n",
            "| 에폭 1 |  반복 141 / 351 | 시간 9[s] | 손실 1.79\n",
            "| 에폭 1 |  반복 161 / 351 | 시간 10[s] | 손실 1.78\n",
            "| 에폭 1 |  반복 181 / 351 | 시간 11[s] | 손실 1.77\n",
            "| 에폭 1 |  반복 201 / 351 | 시간 12[s] | 손실 1.77\n",
            "| 에폭 1 |  반복 221 / 351 | 시간 14[s] | 손실 1.76\n",
            "| 에폭 1 |  반복 241 / 351 | 시간 15[s] | 손실 1.75\n",
            "| 에폭 1 |  반복 261 / 351 | 시간 16[s] | 손실 1.75\n",
            "| 에폭 1 |  반복 281 / 351 | 시간 18[s] | 손실 1.74\n",
            "| 에폭 1 |  반복 301 / 351 | 시간 19[s] | 손실 1.74\n",
            "| 에폭 1 |  반복 321 / 351 | 시간 20[s] | 손실 1.74\n",
            "| 에폭 1 |  반복 341 / 351 | 시간 21[s] | 손실 1.73\n",
            "Q 77+85  \n",
            "T 162 \n",
            "\u001b[91m☒\u001b[0m 100 \n",
            "---\n",
            "Q 975+164\n",
            "T 1139\n",
            "\u001b[91m☒\u001b[0m 1000\n",
            "---\n",
            "Q 582+84 \n",
            "T 666 \n",
            "\u001b[91m☒\u001b[0m 1000\n",
            "---\n",
            "Q 8+155  \n",
            "T 163 \n",
            "\u001b[91m☒\u001b[0m 100 \n",
            "---\n",
            "Q 367+55 \n",
            "T 422 \n",
            "\u001b[91m☒\u001b[0m 1000\n",
            "---\n",
            "Q 600+257\n",
            "T 857 \n",
            "\u001b[91m☒\u001b[0m 1000\n",
            "---\n",
            "Q 761+292\n",
            "T 1053\n",
            "\u001b[91m☒\u001b[0m 1000\n",
            "---\n",
            "Q 830+597\n",
            "T 1427\n",
            "\u001b[91m☒\u001b[0m 1000\n",
            "---\n",
            "Q 26+838 \n",
            "T 864 \n",
            "\u001b[91m☒\u001b[0m 1000\n",
            "---\n",
            "Q 143+93 \n",
            "T 236 \n",
            "\u001b[91m☒\u001b[0m 100 \n",
            "---\n",
            "검증 정확도 0.180%\n",
            "| 에폭 2 |  반복 1 / 351 | 시간 0[s] | 손실 1.73\n",
            "| 에폭 2 |  반복 21 / 351 | 시간 1[s] | 손실 1.73\n",
            "| 에폭 2 |  반복 41 / 351 | 시간 2[s] | 손실 1.72\n",
            "| 에폭 2 |  반복 61 / 351 | 시간 3[s] | 손실 1.72\n",
            "| 에폭 2 |  반복 81 / 351 | 시간 5[s] | 손실 1.72\n",
            "| 에폭 2 |  반복 101 / 351 | 시간 6[s] | 손실 1.72\n",
            "| 에폭 2 |  반복 121 / 351 | 시간 7[s] | 손실 1.71\n",
            "| 에폭 2 |  반복 141 / 351 | 시간 8[s] | 손실 1.71\n",
            "| 에폭 2 |  반복 161 / 351 | 시간 10[s] | 손실 1.70\n",
            "| 에폭 2 |  반복 181 / 351 | 시간 11[s] | 손실 1.70\n",
            "| 에폭 2 |  반복 201 / 351 | 시간 12[s] | 손실 1.70\n",
            "| 에폭 2 |  반복 221 / 351 | 시간 13[s] | 손실 1.69\n",
            "| 에폭 2 |  반복 241 / 351 | 시간 15[s] | 손실 1.69\n",
            "| 에폭 2 |  반복 261 / 351 | 시간 16[s] | 손실 1.69\n",
            "| 에폭 2 |  반복 281 / 351 | 시간 17[s] | 손실 1.69\n",
            "| 에폭 2 |  반복 301 / 351 | 시간 19[s] | 손실 1.68\n",
            "| 에폭 2 |  반복 321 / 351 | 시간 20[s] | 손실 1.68\n",
            "| 에폭 2 |  반복 341 / 351 | 시간 21[s] | 손실 1.68\n",
            "Q 77+85  \n",
            "T 162 \n",
            "\u001b[91m☒\u001b[0m 100 \n",
            "---\n",
            "Q 975+164\n",
            "T 1139\n",
            "\u001b[91m☒\u001b[0m 1277\n",
            "---\n",
            "Q 582+84 \n",
            "T 666 \n",
            "\u001b[91m☒\u001b[0m 700 \n",
            "---\n",
            "Q 8+155  \n",
            "T 163 \n",
            "\u001b[91m☒\u001b[0m 100 \n",
            "---\n",
            "Q 367+55 \n",
            "T 422 \n",
            "\u001b[91m☒\u001b[0m 400 \n",
            "---\n",
            "Q 600+257\n",
            "T 857 \n",
            "\u001b[91m☒\u001b[0m 1000\n",
            "---\n",
            "Q 761+292\n",
            "T 1053\n",
            "\u001b[91m☒\u001b[0m 1007\n",
            "---\n",
            "Q 830+597\n",
            "T 1427\n",
            "\u001b[91m☒\u001b[0m 1277\n",
            "---\n",
            "Q 26+838 \n",
            "T 864 \n",
            "\u001b[91m☒\u001b[0m 400 \n",
            "---\n",
            "Q 143+93 \n",
            "T 236 \n",
            "\u001b[91m☒\u001b[0m 200 \n",
            "---\n",
            "검증 정확도 0.260%\n",
            "| 에폭 3 |  반복 1 / 351 | 시간 0[s] | 손실 1.66\n",
            "| 에폭 3 |  반복 21 / 351 | 시간 1[s] | 손실 1.66\n",
            "| 에폭 3 |  반복 41 / 351 | 시간 2[s] | 손실 1.65\n",
            "| 에폭 3 |  반복 61 / 351 | 시간 3[s] | 손실 1.64\n",
            "| 에폭 3 |  반복 81 / 351 | 시간 5[s] | 손실 1.63\n",
            "| 에폭 3 |  반복 101 / 351 | 시간 6[s] | 손실 1.63\n",
            "| 에폭 3 |  반복 121 / 351 | 시간 7[s] | 손실 1.61\n",
            "| 에폭 3 |  반복 141 / 351 | 시간 10[s] | 손실 1.59\n",
            "| 에폭 3 |  반복 161 / 351 | 시간 14[s] | 손실 1.58\n",
            "| 에폭 3 |  반복 181 / 351 | 시간 18[s] | 손실 1.57\n",
            "| 에폭 3 |  반복 201 / 351 | 시간 19[s] | 손실 1.55\n",
            "| 에폭 3 |  반복 221 / 351 | 시간 21[s] | 손실 1.54\n",
            "| 에폭 3 |  반복 241 / 351 | 시간 22[s] | 손실 1.52\n",
            "| 에폭 3 |  반복 261 / 351 | 시간 23[s] | 손실 1.52\n",
            "| 에폭 3 |  반복 281 / 351 | 시간 25[s] | 손실 1.51\n",
            "| 에폭 3 |  반복 301 / 351 | 시간 26[s] | 손실 1.49\n",
            "| 에폭 3 |  반복 321 / 351 | 시간 27[s] | 손실 1.48\n",
            "| 에폭 3 |  반복 341 / 351 | 시간 29[s] | 손실 1.47\n",
            "Q 77+85  \n",
            "T 162 \n",
            "\u001b[91m☒\u001b[0m 101 \n",
            "---\n",
            "Q 975+164\n",
            "T 1139\n",
            "\u001b[91m☒\u001b[0m 1510\n",
            "---\n",
            "Q 582+84 \n",
            "T 666 \n",
            "\u001b[91m☒\u001b[0m 681 \n",
            "---\n",
            "Q 8+155  \n",
            "T 163 \n",
            "\u001b[91m☒\u001b[0m 111 \n",
            "---\n",
            "Q 367+55 \n",
            "T 422 \n",
            "\u001b[91m☒\u001b[0m 481 \n",
            "---\n",
            "Q 600+257\n",
            "T 857 \n",
            "\u001b[91m☒\u001b[0m 811 \n",
            "---\n",
            "Q 761+292\n",
            "T 1053\n",
            "\u001b[91m☒\u001b[0m 1001\n",
            "---\n",
            "Q 830+597\n",
            "T 1427\n",
            "\u001b[91m☒\u001b[0m 1311\n",
            "---\n",
            "Q 26+838 \n",
            "T 864 \n",
            "\u001b[91m☒\u001b[0m 881 \n",
            "---\n",
            "Q 143+93 \n",
            "T 236 \n",
            "\u001b[91m☒\u001b[0m 381 \n",
            "---\n",
            "검증 정확도 0.580%\n",
            "| 에폭 4 |  반복 1 / 351 | 시간 0[s] | 손실 1.47\n",
            "| 에폭 4 |  반복 21 / 351 | 시간 1[s] | 손실 1.46\n",
            "| 에폭 4 |  반복 41 / 351 | 시간 2[s] | 손실 1.44\n",
            "| 에폭 4 |  반복 61 / 351 | 시간 4[s] | 손실 1.44\n",
            "| 에폭 4 |  반복 81 / 351 | 시간 5[s] | 손실 1.42\n",
            "| 에폭 4 |  반복 101 / 351 | 시간 6[s] | 손실 1.42\n",
            "| 에폭 4 |  반복 121 / 351 | 시간 8[s] | 손실 1.41\n",
            "| 에폭 4 |  반복 141 / 351 | 시간 9[s] | 손실 1.40\n",
            "| 에폭 4 |  반복 161 / 351 | 시간 10[s] | 손실 1.38\n",
            "| 에폭 4 |  반복 181 / 351 | 시간 12[s] | 손실 1.38\n",
            "| 에폭 4 |  반복 201 / 351 | 시간 13[s] | 손실 1.37\n",
            "| 에폭 4 |  반복 221 / 351 | 시간 14[s] | 손실 1.36\n",
            "| 에폭 4 |  반복 241 / 351 | 시간 16[s] | 손실 1.35\n",
            "| 에폭 4 |  반복 261 / 351 | 시간 17[s] | 손실 1.34\n",
            "| 에폭 4 |  반복 281 / 351 | 시간 18[s] | 손실 1.34\n",
            "| 에폭 4 |  반복 301 / 351 | 시간 20[s] | 손실 1.33\n",
            "| 에폭 4 |  반복 321 / 351 | 시간 21[s] | 손실 1.32\n",
            "| 에폭 4 |  반복 341 / 351 | 시간 24[s] | 손실 1.31\n",
            "Q 77+85  \n",
            "T 162 \n",
            "\u001b[91m☒\u001b[0m 155 \n",
            "---\n",
            "Q 975+164\n",
            "T 1139\n",
            "\u001b[91m☒\u001b[0m 1273\n",
            "---\n",
            "Q 582+84 \n",
            "T 666 \n",
            "\u001b[91m☒\u001b[0m 697 \n",
            "---\n",
            "Q 8+155  \n",
            "T 163 \n",
            "\u001b[91m☒\u001b[0m 177 \n",
            "---\n",
            "Q 367+55 \n",
            "T 422 \n",
            "\u001b[91m☒\u001b[0m 419 \n",
            "---\n",
            "Q 600+257\n",
            "T 857 \n",
            "\u001b[91m☒\u001b[0m 895 \n",
            "---\n",
            "Q 761+292\n",
            "T 1053\n",
            "\u001b[91m☒\u001b[0m 1039\n",
            "---\n",
            "Q 830+597\n",
            "T 1427\n",
            "\u001b[91m☒\u001b[0m 1545\n",
            "---\n",
            "Q 26+838 \n",
            "T 864 \n",
            "\u001b[91m☒\u001b[0m 835 \n",
            "---\n",
            "Q 143+93 \n",
            "T 236 \n",
            "\u001b[91m☒\u001b[0m 277 \n",
            "---\n",
            "검증 정확도 1.160%\n",
            "| 에폭 5 |  반복 1 / 351 | 시간 0[s] | 손실 1.29\n",
            "| 에폭 5 |  반복 21 / 351 | 시간 1[s] | 손실 1.29\n",
            "| 에폭 5 |  반복 41 / 351 | 시간 2[s] | 손실 1.28\n",
            "| 에폭 5 |  반복 61 / 351 | 시간 3[s] | 손실 1.28\n",
            "| 에폭 5 |  반복 81 / 351 | 시간 5[s] | 손실 1.27\n",
            "| 에폭 5 |  반복 101 / 351 | 시간 6[s] | 손실 1.28\n",
            "| 에폭 5 |  반복 121 / 351 | 시간 7[s] | 손실 1.28\n",
            "| 에폭 5 |  반복 141 / 351 | 시간 9[s] | 손실 1.26\n",
            "| 에폭 5 |  반복 161 / 351 | 시간 10[s] | 손실 1.25\n",
            "| 에폭 5 |  반복 181 / 351 | 시간 11[s] | 손실 1.24\n",
            "| 에폭 5 |  반복 201 / 351 | 시간 12[s] | 손실 1.23\n",
            "| 에폭 5 |  반복 221 / 351 | 시간 14[s] | 손실 1.23\n",
            "| 에폭 5 |  반복 241 / 351 | 시간 15[s] | 손실 1.22\n",
            "| 에폭 5 |  반복 261 / 351 | 시간 16[s] | 손실 1.22\n",
            "| 에폭 5 |  반복 281 / 351 | 시간 18[s] | 손실 1.22\n",
            "| 에폭 5 |  반복 301 / 351 | 시간 19[s] | 손실 1.21\n",
            "| 에폭 5 |  반복 321 / 351 | 시간 20[s] | 손실 1.21\n",
            "| 에폭 5 |  반복 341 / 351 | 시간 21[s] | 손실 1.20\n",
            "Q 77+85  \n",
            "T 162 \n",
            "\u001b[91m☒\u001b[0m 141 \n",
            "---\n",
            "Q 975+164\n",
            "T 1139\n",
            "\u001b[91m☒\u001b[0m 1224\n",
            "---\n",
            "Q 582+84 \n",
            "T 666 \n",
            "\u001b[91m☒\u001b[0m 677 \n",
            "---\n",
            "Q 8+155  \n",
            "T 163 \n",
            "\u001b[91m☒\u001b[0m 170 \n",
            "---\n",
            "Q 367+55 \n",
            "T 422 \n",
            "\u001b[91m☒\u001b[0m 441 \n",
            "---\n",
            "Q 600+257\n",
            "T 857 \n",
            "\u001b[91m☒\u001b[0m 877 \n",
            "---\n",
            "Q 761+292\n",
            "T 1053\n",
            "\u001b[91m☒\u001b[0m 1024\n",
            "---\n",
            "Q 830+597\n",
            "T 1427\n",
            "\u001b[91m☒\u001b[0m 1444\n",
            "---\n",
            "Q 26+838 \n",
            "T 864 \n",
            "\u001b[91m☒\u001b[0m 847 \n",
            "---\n",
            "Q 143+93 \n",
            "T 236 \n",
            "\u001b[91m☒\u001b[0m 271 \n",
            "---\n",
            "검증 정확도 2.180%\n",
            "| 에폭 6 |  반복 1 / 351 | 시간 0[s] | 손실 1.21\n",
            "| 에폭 6 |  반복 21 / 351 | 시간 1[s] | 손실 1.19\n",
            "| 에폭 6 |  반복 41 / 351 | 시간 2[s] | 손실 1.18\n",
            "| 에폭 6 |  반복 61 / 351 | 시간 4[s] | 손실 1.18\n",
            "| 에폭 6 |  반복 81 / 351 | 시간 5[s] | 손실 1.17\n",
            "| 에폭 6 |  반복 101 / 351 | 시간 7[s] | 손실 1.17\n",
            "| 에폭 6 |  반복 121 / 351 | 시간 8[s] | 손실 1.16\n",
            "| 에폭 6 |  반복 141 / 351 | 시간 9[s] | 손실 1.15\n",
            "| 에폭 6 |  반복 161 / 351 | 시간 10[s] | 손실 1.15\n",
            "| 에폭 6 |  반복 181 / 351 | 시간 12[s] | 손실 1.14\n",
            "| 에폭 6 |  반복 201 / 351 | 시간 13[s] | 손실 1.14\n",
            "| 에폭 6 |  반복 221 / 351 | 시간 14[s] | 손실 1.14\n",
            "| 에폭 6 |  반복 241 / 351 | 시간 15[s] | 손실 1.13\n",
            "| 에폭 6 |  반복 261 / 351 | 시간 17[s] | 손실 1.13\n",
            "| 에폭 6 |  반복 281 / 351 | 시간 18[s] | 손실 1.13\n",
            "| 에폭 6 |  반복 301 / 351 | 시간 19[s] | 손실 1.12\n",
            "| 에폭 6 |  반복 321 / 351 | 시간 21[s] | 손실 1.11\n",
            "| 에폭 6 |  반복 341 / 351 | 시간 22[s] | 손실 1.11\n",
            "Q 77+85  \n",
            "T 162 \n",
            "\u001b[91m☒\u001b[0m 151 \n",
            "---\n",
            "Q 975+164\n",
            "T 1139\n",
            "\u001b[91m☒\u001b[0m 1050\n",
            "---\n",
            "Q 582+84 \n",
            "T 666 \n",
            "\u001b[91m☒\u001b[0m 660 \n",
            "---\n",
            "Q 8+155  \n",
            "T 163 \n",
            "\u001b[91m☒\u001b[0m 150 \n",
            "---\n",
            "Q 367+55 \n",
            "T 422 \n",
            "\u001b[91m☒\u001b[0m 401 \n",
            "---\n",
            "Q 600+257\n",
            "T 857 \n",
            "\u001b[91m☒\u001b[0m 859 \n",
            "---\n",
            "Q 761+292\n",
            "T 1053\n",
            "\u001b[91m☒\u001b[0m 1050\n",
            "---\n",
            "Q 830+597\n",
            "T 1427\n",
            "\u001b[91m☒\u001b[0m 1470\n",
            "---\n",
            "Q 26+838 \n",
            "T 864 \n",
            "\u001b[91m☒\u001b[0m 890 \n",
            "---\n",
            "Q 143+93 \n",
            "T 236 \n",
            "\u001b[91m☒\u001b[0m 208 \n",
            "---\n",
            "검증 정확도 1.940%\n",
            "| 에폭 7 |  반복 1 / 351 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 7 |  반복 21 / 351 | 시간 1[s] | 손실 1.10\n",
            "| 에폭 7 |  반복 41 / 351 | 시간 2[s] | 손실 1.12\n",
            "| 에폭 7 |  반복 61 / 351 | 시간 4[s] | 손실 1.10\n",
            "| 에폭 7 |  반복 81 / 351 | 시간 6[s] | 손실 1.10\n",
            "| 에폭 7 |  반복 101 / 351 | 시간 9[s] | 손실 1.10\n",
            "| 에폭 7 |  반복 121 / 351 | 시간 10[s] | 손실 1.08\n",
            "| 에폭 7 |  반복 141 / 351 | 시간 12[s] | 손실 1.07\n",
            "| 에폭 7 |  반복 161 / 351 | 시간 13[s] | 손실 1.07\n",
            "| 에폭 7 |  반복 181 / 351 | 시간 14[s] | 손실 1.08\n",
            "| 에폭 7 |  반복 201 / 351 | 시간 16[s] | 손실 1.09\n",
            "| 에폭 7 |  반복 221 / 351 | 시간 17[s] | 손실 1.07\n",
            "| 에폭 7 |  반복 241 / 351 | 시간 19[s] | 손실 1.06\n",
            "| 에폭 7 |  반복 261 / 351 | 시간 20[s] | 손실 1.05\n",
            "| 에폭 7 |  반복 281 / 351 | 시간 21[s] | 손실 1.07\n",
            "| 에폭 7 |  반복 301 / 351 | 시간 23[s] | 손실 1.05\n",
            "| 에폭 7 |  반복 321 / 351 | 시간 24[s] | 손실 1.08\n",
            "| 에폭 7 |  반복 341 / 351 | 시간 25[s] | 손실 1.05\n",
            "Q 77+85  \n",
            "T 162 \n",
            "\u001b[91m☒\u001b[0m 155 \n",
            "---\n",
            "Q 975+164\n",
            "T 1139\n",
            "\u001b[91m☒\u001b[0m 1098\n",
            "---\n",
            "Q 582+84 \n",
            "T 666 \n",
            "\u001b[91m☒\u001b[0m 661 \n",
            "---\n",
            "Q 8+155  \n",
            "T 163 \n",
            "\u001b[91m☒\u001b[0m 155 \n",
            "---\n",
            "Q 367+55 \n",
            "T 422 \n",
            "\u001b[91m☒\u001b[0m 405 \n",
            "---\n",
            "Q 600+257\n",
            "T 857 \n",
            "\u001b[91m☒\u001b[0m 858 \n",
            "---\n",
            "Q 761+292\n",
            "T 1053\n",
            "\u001b[91m☒\u001b[0m 1035\n",
            "---\n",
            "Q 830+597\n",
            "T 1427\n",
            "\u001b[91m☒\u001b[0m 1430\n",
            "---\n",
            "Q 26+838 \n",
            "T 864 \n",
            "\u001b[91m☒\u001b[0m 871 \n",
            "---\n",
            "Q 143+93 \n",
            "T 236 \n",
            "\u001b[91m☒\u001b[0m 209 \n",
            "---\n",
            "검증 정확도 3.620%\n",
            "| 에폭 8 |  반복 1 / 351 | 시간 0[s] | 손실 1.05\n",
            "| 에폭 8 |  반복 21 / 351 | 시간 1[s] | 손실 1.06\n",
            "| 에폭 8 |  반복 41 / 351 | 시간 2[s] | 손실 1.06\n",
            "| 에폭 8 |  반복 61 / 351 | 시간 3[s] | 손실 1.04\n",
            "| 에폭 8 |  반복 81 / 351 | 시간 5[s] | 손실 1.05\n",
            "| 에폭 8 |  반복 101 / 351 | 시간 6[s] | 손실 1.03\n",
            "| 에폭 8 |  반복 121 / 351 | 시간 7[s] | 손실 1.03\n",
            "| 에폭 8 |  반복 141 / 351 | 시간 9[s] | 손실 1.04\n",
            "| 에폭 8 |  반복 161 / 351 | 시간 11[s] | 손실 1.04\n",
            "| 에폭 8 |  반복 181 / 351 | 시간 12[s] | 손실 1.04\n",
            "| 에폭 8 |  반복 201 / 351 | 시간 14[s] | 손실 1.03\n",
            "| 에폭 8 |  반복 221 / 351 | 시간 15[s] | 손실 1.03\n",
            "| 에폭 8 |  반복 241 / 351 | 시간 16[s] | 손실 1.03\n",
            "| 에폭 8 |  반복 261 / 351 | 시간 18[s] | 손실 1.02\n",
            "| 에폭 8 |  반복 281 / 351 | 시간 19[s] | 손실 1.02\n",
            "| 에폭 8 |  반복 301 / 351 | 시간 20[s] | 손실 1.01\n",
            "| 에폭 8 |  반복 321 / 351 | 시간 22[s] | 손실 1.02\n",
            "| 에폭 8 |  반복 341 / 351 | 시간 25[s] | 손실 1.01\n",
            "Q 77+85  \n",
            "T 162 \n",
            "\u001b[91m☒\u001b[0m 159 \n",
            "---\n",
            "Q 975+164\n",
            "T 1139\n",
            "\u001b[91m☒\u001b[0m 1111\n",
            "---\n",
            "Q 582+84 \n",
            "T 666 \n",
            "\u001b[91m☒\u001b[0m 671 \n",
            "---\n",
            "Q 8+155  \n",
            "T 163 \n",
            "\u001b[91m☒\u001b[0m 159 \n",
            "---\n",
            "Q 367+55 \n",
            "T 422 \n",
            "\u001b[91m☒\u001b[0m 405 \n",
            "---\n",
            "Q 600+257\n",
            "T 857 \n",
            "\u001b[91m☒\u001b[0m 871 \n",
            "---\n",
            "Q 761+292\n",
            "T 1053\n",
            "\u001b[91m☒\u001b[0m 1074\n",
            "---\n",
            "Q 830+597\n",
            "T 1427\n",
            "\u001b[91m☒\u001b[0m 1444\n",
            "---\n",
            "Q 26+838 \n",
            "T 864 \n",
            "\u001b[91m☒\u001b[0m 871 \n",
            "---\n",
            "Q 143+93 \n",
            "T 236 \n",
            "\u001b[91m☒\u001b[0m 209 \n",
            "---\n",
            "검증 정확도 4.260%\n",
            "| 에폭 9 |  반복 1 / 351 | 시간 0[s] | 손실 1.02\n",
            "| 에폭 9 |  반복 21 / 351 | 시간 1[s] | 손실 1.01\n",
            "| 에폭 9 |  반복 41 / 351 | 시간 2[s] | 손실 1.00\n",
            "| 에폭 9 |  반복 61 / 351 | 시간 4[s] | 손실 1.01\n",
            "| 에폭 9 |  반복 81 / 351 | 시간 5[s] | 손실 1.03\n",
            "| 에폭 9 |  반복 101 / 351 | 시간 6[s] | 손실 1.04\n",
            "| 에폭 9 |  반복 121 / 351 | 시간 7[s] | 손실 1.04\n",
            "| 에폭 9 |  반복 141 / 351 | 시간 9[s] | 손실 1.02\n",
            "| 에폭 9 |  반복 161 / 351 | 시간 10[s] | 손실 1.00\n",
            "| 에폭 9 |  반복 181 / 351 | 시간 11[s] | 손실 1.00\n",
            "| 에폭 9 |  반복 201 / 351 | 시간 13[s] | 손실 0.99\n",
            "| 에폭 9 |  반복 221 / 351 | 시간 14[s] | 손실 0.98\n",
            "| 에폭 9 |  반복 241 / 351 | 시간 15[s] | 손실 0.99\n",
            "| 에폭 9 |  반복 261 / 351 | 시간 17[s] | 손실 1.04\n",
            "| 에폭 9 |  반복 281 / 351 | 시간 18[s] | 손실 1.00\n",
            "| 에폭 9 |  반복 301 / 351 | 시간 19[s] | 손실 0.98\n",
            "| 에폭 9 |  반복 321 / 351 | 시간 21[s] | 손실 0.98\n",
            "| 에폭 9 |  반복 341 / 351 | 시간 22[s] | 손실 0.99\n",
            "Q 77+85  \n",
            "T 162 \n",
            "\u001b[91m☒\u001b[0m 155 \n",
            "---\n",
            "Q 975+164\n",
            "T 1139\n",
            "\u001b[91m☒\u001b[0m 1115\n",
            "---\n",
            "Q 582+84 \n",
            "T 666 \n",
            "\u001b[91m☒\u001b[0m 667 \n",
            "---\n",
            "Q 8+155  \n",
            "T 163 \n",
            "\u001b[91m☒\u001b[0m 154 \n",
            "---\n",
            "Q 367+55 \n",
            "T 422 \n",
            "\u001b[91m☒\u001b[0m 415 \n",
            "---\n",
            "Q 600+257\n",
            "T 857 \n",
            "\u001b[91m☒\u001b[0m 854 \n",
            "---\n",
            "Q 761+292\n",
            "T 1053\n",
            "\u001b[91m☒\u001b[0m 1037\n",
            "---\n",
            "Q 830+597\n",
            "T 1427\n",
            "\u001b[91m☒\u001b[0m 1444\n",
            "---\n",
            "Q 26+838 \n",
            "T 864 \n",
            "\u001b[91m☒\u001b[0m 874 \n",
            "---\n",
            "Q 143+93 \n",
            "T 236 \n",
            "\u001b[91m☒\u001b[0m 227 \n",
            "---\n",
            "검증 정확도 4.360%\n",
            "| 에폭 10 |  반복 1 / 351 | 시간 0[s] | 손실 0.97\n",
            "| 에폭 10 |  반복 21 / 351 | 시간 1[s] | 손실 0.97\n",
            "| 에폭 10 |  반복 41 / 351 | 시간 2[s] | 손실 0.98\n",
            "| 에폭 10 |  반복 61 / 351 | 시간 3[s] | 손실 0.97\n",
            "| 에폭 10 |  반복 81 / 351 | 시간 5[s] | 손실 0.99\n",
            "| 에폭 10 |  반복 101 / 351 | 시간 6[s] | 손실 0.98\n",
            "| 에폭 10 |  반복 121 / 351 | 시간 7[s] | 손실 0.97\n",
            "| 에폭 10 |  반복 141 / 351 | 시간 9[s] | 손실 1.00\n",
            "| 에폭 10 |  반복 161 / 351 | 시간 10[s] | 손실 0.99\n",
            "| 에폭 10 |  반복 181 / 351 | 시간 11[s] | 손실 0.95\n",
            "| 에폭 10 |  반복 201 / 351 | 시간 13[s] | 손실 0.96\n",
            "| 에폭 10 |  반복 221 / 351 | 시간 14[s] | 손실 0.96\n",
            "| 에폭 10 |  반복 241 / 351 | 시간 15[s] | 손실 0.96\n",
            "| 에폭 10 |  반복 261 / 351 | 시간 17[s] | 손실 0.95\n",
            "| 에폭 10 |  반복 281 / 351 | 시간 18[s] | 손실 0.96\n",
            "| 에폭 10 |  반복 301 / 351 | 시간 19[s] | 손실 0.94\n",
            "| 에폭 10 |  반복 321 / 351 | 시간 22[s] | 손실 0.97\n",
            "| 에폭 10 |  반복 341 / 351 | 시간 25[s] | 손실 0.95\n",
            "Q 77+85  \n",
            "T 162 \n",
            "\u001b[91m☒\u001b[0m 160 \n",
            "---\n",
            "Q 975+164\n",
            "T 1139\n",
            "\u001b[91m☒\u001b[0m 1172\n",
            "---\n",
            "Q 582+84 \n",
            "T 666 \n",
            "\u001b[91m☒\u001b[0m 673 \n",
            "---\n",
            "Q 8+155  \n",
            "T 163 \n",
            "\u001b[91m☒\u001b[0m 157 \n",
            "---\n",
            "Q 367+55 \n",
            "T 422 \n",
            "\u001b[91m☒\u001b[0m 415 \n",
            "---\n",
            "Q 600+257\n",
            "T 857 \n",
            "\u001b[91m☒\u001b[0m 847 \n",
            "---\n",
            "Q 761+292\n",
            "T 1053\n",
            "\u001b[91m☒\u001b[0m 1062\n",
            "---\n",
            "Q 830+597\n",
            "T 1427\n",
            "\u001b[91m☒\u001b[0m 1453\n",
            "---\n",
            "Q 26+838 \n",
            "T 864 \n",
            "\u001b[91m☒\u001b[0m 871 \n",
            "---\n",
            "Q 143+93 \n",
            "T 236 \n",
            "\u001b[91m☒\u001b[0m 232 \n",
            "---\n",
            "검증 정확도 5.880%\n",
            "| 에폭 11 |  반복 1 / 351 | 시간 0[s] | 손실 0.97\n",
            "| 에폭 11 |  반복 21 / 351 | 시간 3[s] | 손실 0.93\n",
            "| 에폭 11 |  반복 41 / 351 | 시간 6[s] | 손실 0.94\n",
            "| 에폭 11 |  반복 61 / 351 | 시간 9[s] | 손실 0.95\n",
            "| 에폭 11 |  반복 81 / 351 | 시간 12[s] | 손실 0.94\n",
            "| 에폭 11 |  반복 101 / 351 | 시간 15[s] | 손실 0.94\n",
            "| 에폭 11 |  반복 121 / 351 | 시간 17[s] | 손실 0.95\n",
            "| 에폭 11 |  반복 141 / 351 | 시간 20[s] | 손실 0.96\n",
            "| 에폭 11 |  반복 161 / 351 | 시간 22[s] | 손실 0.94\n",
            "| 에폭 11 |  반복 181 / 351 | 시간 23[s] | 손실 0.92\n",
            "| 에폭 11 |  반복 201 / 351 | 시간 24[s] | 손실 0.94\n",
            "| 에폭 11 |  반복 221 / 351 | 시간 26[s] | 손실 0.93\n",
            "| 에폭 11 |  반복 241 / 351 | 시간 27[s] | 손실 0.92\n",
            "| 에폭 11 |  반복 261 / 351 | 시간 28[s] | 손실 0.92\n",
            "| 에폭 11 |  반복 281 / 351 | 시간 30[s] | 손실 0.93\n",
            "| 에폭 11 |  반복 301 / 351 | 시간 31[s] | 손실 0.95\n",
            "| 에폭 11 |  반복 321 / 351 | 시간 32[s] | 손실 0.96\n",
            "| 에폭 11 |  반복 341 / 351 | 시간 33[s] | 손실 0.96\n",
            "Q 77+85  \n",
            "T 162 \n",
            "\u001b[91m☒\u001b[0m 163 \n",
            "---\n",
            "Q 975+164\n",
            "T 1139\n",
            "\u001b[91m☒\u001b[0m 1172\n",
            "---\n",
            "Q 582+84 \n",
            "T 666 \n",
            "\u001b[91m☒\u001b[0m 665 \n",
            "---\n",
            "Q 8+155  \n",
            "T 163 \n",
            "\u001b[91m☒\u001b[0m 162 \n",
            "---\n",
            "Q 367+55 \n",
            "T 422 \n",
            "\u001b[91m☒\u001b[0m 419 \n",
            "---\n",
            "Q 600+257\n",
            "T 857 \n",
            "\u001b[91m☒\u001b[0m 855 \n",
            "---\n",
            "Q 761+292\n",
            "T 1053\n",
            "\u001b[91m☒\u001b[0m 1072\n",
            "---\n",
            "Q 830+597\n",
            "T 1427\n",
            "\u001b[91m☒\u001b[0m 1446\n",
            "---\n",
            "Q 26+838 \n",
            "T 864 \n",
            "\u001b[91m☒\u001b[0m 861 \n",
            "---\n",
            "Q 143+93 \n",
            "T 236 \n",
            "\u001b[91m☒\u001b[0m 229 \n",
            "---\n",
            "검증 정확도 5.980%\n",
            "| 에폭 12 |  반복 1 / 351 | 시간 0[s] | 손실 0.93\n",
            "| 에폭 12 |  반복 21 / 351 | 시간 2[s] | 손실 0.92\n",
            "| 에폭 12 |  반복 41 / 351 | 시간 3[s] | 손실 0.91\n",
            "| 에폭 12 |  반복 61 / 351 | 시간 6[s] | 손실 0.94\n",
            "| 에폭 12 |  반복 81 / 351 | 시간 9[s] | 손실 0.93\n",
            "| 에폭 12 |  반복 101 / 351 | 시간 13[s] | 손실 0.91\n",
            "| 에폭 12 |  반복 121 / 351 | 시간 15[s] | 손실 0.92\n",
            "| 에폭 12 |  반복 141 / 351 | 시간 16[s] | 손실 0.92\n",
            "| 에폭 12 |  반복 161 / 351 | 시간 18[s] | 손실 0.93\n",
            "| 에폭 12 |  반복 181 / 351 | 시간 19[s] | 손실 0.93\n",
            "| 에폭 12 |  반복 201 / 351 | 시간 21[s] | 손실 0.91\n",
            "| 에폭 12 |  반복 221 / 351 | 시간 22[s] | 손실 0.91\n",
            "| 에폭 12 |  반복 241 / 351 | 시간 24[s] | 손실 0.91\n",
            "| 에폭 12 |  반복 261 / 351 | 시간 25[s] | 손실 0.90\n",
            "| 에폭 12 |  반복 281 / 351 | 시간 26[s] | 손실 0.91\n",
            "| 에폭 12 |  반복 301 / 351 | 시간 28[s] | 손실 0.93\n",
            "| 에폭 12 |  반복 321 / 351 | 시간 29[s] | 손실 0.91\n",
            "| 에폭 12 |  반복 341 / 351 | 시간 31[s] | 손실 0.91\n",
            "Q 77+85  \n",
            "T 162 \n",
            "\u001b[91m☒\u001b[0m 159 \n",
            "---\n",
            "Q 975+164\n",
            "T 1139\n",
            "\u001b[91m☒\u001b[0m 1160\n",
            "---\n",
            "Q 582+84 \n",
            "T 666 \n",
            "\u001b[91m☒\u001b[0m 660 \n",
            "---\n",
            "Q 8+155  \n",
            "T 163 \n",
            "\u001b[91m☒\u001b[0m 167 \n",
            "---\n",
            "Q 367+55 \n",
            "T 422 \n",
            "\u001b[91m☒\u001b[0m 409 \n",
            "---\n",
            "Q 600+257\n",
            "T 857 \n",
            "\u001b[91m☒\u001b[0m 836 \n",
            "---\n",
            "Q 761+292\n",
            "T 1053\n",
            "\u001b[91m☒\u001b[0m 1039\n",
            "---\n",
            "Q 830+597\n",
            "T 1427\n",
            "\u001b[91m☒\u001b[0m 1440\n",
            "---\n",
            "Q 26+838 \n",
            "T 864 \n",
            "\u001b[91m☒\u001b[0m 859 \n",
            "---\n",
            "Q 143+93 \n",
            "T 236 \n",
            "\u001b[91m☒\u001b[0m 229 \n",
            "---\n",
            "검증 정확도 4.480%\n",
            "| 에폭 13 |  반복 1 / 351 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 13 |  반복 21 / 351 | 시간 1[s] | 손실 0.93\n",
            "| 에폭 13 |  반복 41 / 351 | 시간 2[s] | 손실 0.91\n",
            "| 에폭 13 |  반복 61 / 351 | 시간 3[s] | 손실 0.89\n",
            "| 에폭 13 |  반복 81 / 351 | 시간 5[s] | 손실 0.89\n",
            "| 에폭 13 |  반복 101 / 351 | 시간 6[s] | 손실 0.89\n",
            "| 에폭 13 |  반복 121 / 351 | 시간 8[s] | 손실 0.89\n",
            "| 에폭 13 |  반복 141 / 351 | 시간 9[s] | 손실 0.92\n",
            "| 에폭 13 |  반복 161 / 351 | 시간 10[s] | 손실 0.93\n",
            "| 에폭 13 |  반복 181 / 351 | 시간 11[s] | 손실 0.89\n",
            "| 에폭 13 |  반복 201 / 351 | 시간 13[s] | 손실 0.89\n",
            "| 에폭 13 |  반복 221 / 351 | 시간 14[s] | 손실 0.90\n",
            "| 에폭 13 |  반복 241 / 351 | 시간 15[s] | 손실 0.89\n",
            "| 에폭 13 |  반복 261 / 351 | 시간 17[s] | 손실 0.89\n",
            "| 에폭 13 |  반복 281 / 351 | 시간 18[s] | 손실 0.88\n",
            "| 에폭 13 |  반복 301 / 351 | 시간 19[s] | 손실 0.88\n",
            "| 에폭 13 |  반복 321 / 351 | 시간 21[s] | 손실 0.88\n",
            "| 에폭 13 |  반복 341 / 351 | 시간 22[s] | 손실 0.88\n",
            "Q 77+85  \n",
            "T 162 \n",
            "\u001b[91m☒\u001b[0m 159 \n",
            "---\n",
            "Q 975+164\n",
            "T 1139\n",
            "\u001b[91m☒\u001b[0m 1131\n",
            "---\n",
            "Q 582+84 \n",
            "T 666 \n",
            "\u001b[91m☒\u001b[0m 663 \n",
            "---\n",
            "Q 8+155  \n",
            "T 163 \n",
            "\u001b[92m☑\u001b[0m 163 \n",
            "---\n",
            "Q 367+55 \n",
            "T 422 \n",
            "\u001b[91m☒\u001b[0m 419 \n",
            "---\n",
            "Q 600+257\n",
            "T 857 \n",
            "\u001b[91m☒\u001b[0m 855 \n",
            "---\n",
            "Q 761+292\n",
            "T 1053\n",
            "\u001b[91m☒\u001b[0m 1063\n",
            "---\n",
            "Q 830+597\n",
            "T 1427\n",
            "\u001b[91m☒\u001b[0m 1431\n",
            "---\n",
            "Q 26+838 \n",
            "T 864 \n",
            "\u001b[91m☒\u001b[0m 861 \n",
            "---\n",
            "Q 143+93 \n",
            "T 236 \n",
            "\u001b[91m☒\u001b[0m 239 \n",
            "---\n",
            "검증 정확도 7.960%\n",
            "| 에폭 14 |  반복 1 / 351 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 14 |  반복 21 / 351 | 시간 1[s] | 손실 0.87\n",
            "| 에폭 14 |  반복 41 / 351 | 시간 2[s] | 손실 0.87\n",
            "| 에폭 14 |  반복 61 / 351 | 시간 3[s] | 손실 0.91\n",
            "| 에폭 14 |  반복 81 / 351 | 시간 5[s] | 손실 0.91\n",
            "| 에폭 14 |  반복 101 / 351 | 시간 8[s] | 손실 0.91\n",
            "| 에폭 14 |  반복 121 / 351 | 시간 10[s] | 손실 0.91\n",
            "| 에폭 14 |  반복 141 / 351 | 시간 11[s] | 손실 0.89\n",
            "| 에폭 14 |  반복 161 / 351 | 시간 13[s] | 손실 0.87\n",
            "| 에폭 14 |  반복 181 / 351 | 시간 14[s] | 손실 0.87\n",
            "| 에폭 14 |  반복 201 / 351 | 시간 15[s] | 손실 0.92\n",
            "| 에폭 14 |  반복 221 / 351 | 시간 17[s] | 손실 0.89\n",
            "| 에폭 14 |  반복 241 / 351 | 시간 18[s] | 손실 0.87\n",
            "| 에폭 14 |  반복 261 / 351 | 시간 19[s] | 손실 0.88\n",
            "| 에폭 14 |  반복 281 / 351 | 시간 20[s] | 손실 0.86\n",
            "| 에폭 14 |  반복 301 / 351 | 시간 23[s] | 손실 0.87\n",
            "| 에폭 14 |  반복 321 / 351 | 시간 25[s] | 손실 0.87\n",
            "| 에폭 14 |  반복 341 / 351 | 시간 27[s] | 손실 0.86\n",
            "Q 77+85  \n",
            "T 162 \n",
            "\u001b[91m☒\u001b[0m 166 \n",
            "---\n",
            "Q 975+164\n",
            "T 1139\n",
            "\u001b[91m☒\u001b[0m 1108\n",
            "---\n",
            "Q 582+84 \n",
            "T 666 \n",
            "\u001b[91m☒\u001b[0m 681 \n",
            "---\n",
            "Q 8+155  \n",
            "T 163 \n",
            "\u001b[91m☒\u001b[0m 162 \n",
            "---\n",
            "Q 367+55 \n",
            "T 422 \n",
            "\u001b[91m☒\u001b[0m 418 \n",
            "---\n",
            "Q 600+257\n",
            "T 857 \n",
            "\u001b[91m☒\u001b[0m 866 \n",
            "---\n",
            "Q 761+292\n",
            "T 1053\n",
            "\u001b[91m☒\u001b[0m 1039\n",
            "---\n",
            "Q 830+597\n",
            "T 1427\n",
            "\u001b[91m☒\u001b[0m 1412\n",
            "---\n",
            "Q 26+838 \n",
            "T 864 \n",
            "\u001b[91m☒\u001b[0m 861 \n",
            "---\n",
            "Q 143+93 \n",
            "T 236 \n",
            "\u001b[92m☑\u001b[0m 236 \n",
            "---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-757b0be47750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         correct_num += eval_seq2seq(model, question, correct,\n\u001b[0;32m---> 15\u001b[0;31m                                     id_to_char, verbose)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_num\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-6415c7bbb48b>\u001b[0m in \u001b[0;36meval_seq2seq\u001b[0;34m(model, question, correct, id_to_char, verbos, is_reverse)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstart_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mguess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# 문자열로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-c87042ff7b04>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, xs, start_id, sample_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0msampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msampled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-d2698b812e2d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# 마지막 시각의 은닉 상태만 추출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-e195fad194c5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-2ce2953b3693>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h_prev, c_prev)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_prev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dphfbKRkvBHG",
        "outputId": "71ea5cfe-a9be-4f9c-d8bc-4fa1582233aa"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45000"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "max_iters 가 45000//128 = 351 이어서 351번을 수행하기에 너무 오래걸려서 여기서 멈추어보았습니다."
      ],
      "metadata": {
        "id": "0rHymMfJu-bM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-6T8ZkWSqoBY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}